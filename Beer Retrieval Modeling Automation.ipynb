{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting stepfunctions\n",
      "  Using cached stepfunctions-2.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sagemaker>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from stepfunctions) (2.68.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from stepfunctions) (6.0)\n",
      "Requirement already satisfied: boto3>=1.14.38 in /opt/conda/lib/python3.7/site-packages (from stepfunctions) (1.20.4)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.14.38->stepfunctions) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.14.38->stepfunctions) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.4 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.14.38->stepfunctions) (1.23.4)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (0.2.8)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (19.3.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (0.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (1.5.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (3.19.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (20.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (1.0.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.1.0->stepfunctions) (1.20.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.4->boto3>=1.14.38->stepfunctions) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.4->boto3>=1.14.38->stepfunctions) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.1.0->stepfunctions) (2.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker>=2.1.0->stepfunctions) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker>=2.1.0->stepfunctions) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker>=2.1.0->stepfunctions) (2019.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.1.0->stepfunctions) (0.70.12.2)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.1.0->stepfunctions) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.1.0->stepfunctions) (0.3.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.1.0->stepfunctions) (0.3.0)\n",
      "Installing collected packages: stepfunctions\n",
      "Successfully installed stepfunctions-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Name: sagemaker\n",
      "Version: 2.68.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: attrs, boto3, google-pasta, importlib-metadata, numpy, packaging, pandas, pathos, protobuf, protobuf3-to-dict, smdebug-rulesconfig\n",
      "Required-by: stepfunctions\n",
      "---\n",
      "Name: stepfunctions\n",
      "Version: 2.2.0\n",
      "Summary: Open source library for develping data science workflows on AWS Step Functions.\n",
      "Home-page: https://github.com/aws/aws-step-functions-data-science-sdk-python\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: boto3, pyyaml, sagemaker\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install stepfunctions\n",
    "!pip show sagemaker stepfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepfunctions\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.steps import (\n",
    "    Chain,\n",
    "    ChoiceRule,\n",
    "    ModelStep,\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    "    TransformStep,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "from stepfunctions.template import TrainingPipeline\n",
    "from stepfunctions.template.utils import replace_parameters_with_jsonpath\n",
    "from stepfunctions.workflow import Workflow\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.68.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_execution_role = \"(your workflow execution role here)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine My Reviews With Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StepFunction Workflow Execution Input Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create customer training container for TF probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker expects unique names for each job, model and endpoint.\n",
    "# If these names are not unique the execution will fail. Pass these\n",
    "# dynamically for each execution using placeholders.\n",
    "execution_input = ExecutionInput(\n",
    "    schema={\n",
    "        \"ProcessingJobName\": str,\n",
    "        \"TrainingJobName\": str,\n",
    "        \"SaveModelJobName\": str,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set To True For Testing\n",
    "testing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Preprocessing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# need to use ml.m5.2xlarge to have enough memory - can be scaled to larger instance if we have more data\n",
    "sklearn_processing = SKLearnProcessor(\n",
    "    framework_version=\"0.20.0\", role=role, instance_type=\"ml.m5.xlarge\", instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting retrieval_preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile retrieval_preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def users_test_train_split(df, split_ratio=0.1):\n",
    "    unique_users = df['username'].unique()\n",
    "    \n",
    "    test_user_len = int(len(unique_users)*split_ratio)\n",
    "    \n",
    "    test_df = df[df['username'].isin(unique_users[:test_user_len])]\n",
    "    train_df = df[~df['username'].isin(unique_users[:test_user_len])]\n",
    "    \n",
    "    return test_df, train_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_data_path_reviews = os.path.join(\"/opt/ml/processing/input/reviews\", \"final_reviews.csv\")\n",
    "    \n",
    "    train_output_path = os.path.join(\"/opt/ml/processing/output/train_data\", \"retrieval_train.csv\")\n",
    "    test_output_path = os.path.join(\"/opt/ml/processing/output/test_data\", \"retrieval_test.csv\")\n",
    "    \n",
    "    print(\"Reading review input data from {}\".format(input_data_path_reviews))\n",
    "    review_df = pd.read_csv(input_data_path_reviews, index_col=\"Unnamed: 0\")\n",
    "    \n",
    "    # Shuffle dataframe\n",
    "    review_df = review_df.sample(frac=1)\n",
    "    \n",
    "    # only get users with at least 5 reviews\n",
    "    users_with_favorable_ratings = (review_df['username'].value_counts()\n",
    "                                .loc[lambda x: x>10]\n",
    "                                .loc[lambda x: x<100]\n",
    "                                .index.values)\n",
    "    \n",
    "    review_df = review_df[review_df['username'].isin(users_with_favorable_ratings)]\n",
    "    \n",
    "    #Generate test train split\n",
    "    test_df, train_df = users_test_train_split(review_df)\n",
    "    \n",
    "    \n",
    "    print(\"Saving Train Data {}\".format(train_output_path))\n",
    "    train_df.to_csv(train_output_path, header=True, index=True)\n",
    "    \n",
    "    print(\"Saving Test Data {}\".format(test_output_path))\n",
    "    test_df.to_csv(test_output_path, header=True, index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket pathing\n",
    "input_reviews = \"s3://beer-reviews-models-pb/Rec Automation/Review Data/Initial Data/final_reviews.csv\".format(region)\n",
    "\n",
    "output_folder_train = \"s3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Train\".format(region)\n",
    "output_folder_test = \"s3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Test\".format(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSING_SCRIPT_LOCATION = \"retrieval_preprocessing.py\"\n",
    "\n",
    "processing_code = sagemaker_session.upload_data(\n",
    "    PROCESSING_SCRIPT_LOCATION,\n",
    "    bucket=\"beer-reviews-models-pb\",\n",
    "    key_prefix=\"Rec Automation/Job Scripts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2021-11-17-23-04-53-863\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Initial Data/final_reviews.csv', 'LocalPath': '/opt/ml/processing/input/reviews', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Job Scripts/retrieval_preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'training_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Train', 'LocalPath': '/opt/ml/processing/output/train_data', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Test', 'LocalPath': '/opt/ml/processing/output/test_data', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".......................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReading review input data from /opt/ml/processing/input/reviews/final_reviews.csv\u001b[0m\n",
      "\u001b[34mSaving Train Data /opt/ml/processing/output/train_data/retrieval_train.csv\u001b[0m\n",
      "\u001b[34mSaving Test Data /opt/ml/processing/output/test_data/retrieval_test.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "if testing:\n",
    "    \n",
    "    # Test labeling job (only run once to check functionality)\n",
    "    sklearn_processing.run(\n",
    "        code=processing_code,\n",
    "        inputs=[\n",
    "                ProcessingInput(source=input_reviews, destination=\"/opt/ml/processing/input/reviews\"),\n",
    "            ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"training_data\", source=\"/opt/ml/processing/output/train_data\", destination = output_folder_train),\n",
    "            ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test_data\", destination = output_folder_test),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "else: \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Initial Data/final_reviews.csv', 'LocalPath': '/opt/ml/processing/input/reviews', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Job Scripts/retrieval_preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'training_data', 'S3Output': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Train', 'LocalPath': '/opt/ml/processing/output/train_data', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Test', 'LocalPath': '/opt/ml/processing/output/test_data', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'sagemaker-scikit-learn-2021-11-16-20-19-25-451', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/retrieval_preprocessing.py']}, 'RoleArn': 'arn:aws:iam::348278147190:role/service-role/AmazonSageMaker-ExecutionRole-20210908T201427', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-2:348278147190:processing-job/sagemaker-scikit-learn-2021-11-16-20-19-25-451', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2021, 11, 16, 20, 23, 8, 978000, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2021, 11, 16, 20, 22, 48, 849000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2021, 11, 16, 20, 23, 9, 197000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2021, 11, 16, 20, 19, 25, 687000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'de44d486-8ab0-4312-9a7d-673ccf9a9b2b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'de44d486-8ab0-4312-9a7d-673ccf9a9b2b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2134', 'date': 'Tue, 16 Nov 2021 20:42:38 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    \n",
    "    preprocessing_job_description = sklearn_processing.jobs[-1].describe()\n",
    "    print(preprocessing_job_description)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add input code as well\n",
    "\n",
    "processing_inputs = [\n",
    "            \n",
    "            ProcessingInput(source=input_samples, destination=\"/opt/ml/processing/input/reviews\", input_name = \"input review data\"),\n",
    "            ProcessingInput(source = processing_code, destination=\"/opt/ml/processing/input/code\", input_name=\"code\")\n",
    "        ]\n",
    "\n",
    "processing_outputs = [\n",
    "            ProcessingOutput(output_name=\"training_data\", source=\"/opt/ml/processing/output/train_data\", destination = output_folder_train),\n",
    "            ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test_data\", destination = output_folder_test),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_step = ProcessingStep(\n",
    "    \"SageMaker Labeling Step\", \n",
    "    processor = sklearn_processing,\n",
    "    job_name = execution_input[\"ProcessingJobName\"],\n",
    "    inputs = processing_inputs,\n",
    "    outputs = processing_outputs,\n",
    "    container_entrypoint = [\"python3\", '/opt/ml/processing/input/code/retrieval_preprocessing.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>beer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412226</th>\n",
       "      <td>4.03</td>\n",
       "      <td>cantal</td>\n",
       "      <td></td>\n",
       "      <td>American IPA</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Oskar Blues Grill &amp; Brew</td>\n",
       "      <td>Pinner Throwback IPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458058</th>\n",
       "      <td>4.00</td>\n",
       "      <td>warnerry</td>\n",
       "      <td>0%</td>\n",
       "      <td>Belgian Saison</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Crooked Stave Artisan Beer Project</td>\n",
       "      <td>Vieille Artisanal Saison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116967</th>\n",
       "      <td>4.00</td>\n",
       "      <td>NorthCoastPranqster</td>\n",
       "      <td></td>\n",
       "      <td>American Imperial Stout</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Great Divide Brewing Company</td>\n",
       "      <td>Espresso Oak Aged Yeti Imperial Stout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87978</th>\n",
       "      <td>3.88</td>\n",
       "      <td>cvstrickland</td>\n",
       "      <td>12-ounce longneck poured into my DFH pint g...</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Great Divide Brewing Company</td>\n",
       "      <td>Denver Pale Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319909</th>\n",
       "      <td>3.89</td>\n",
       "      <td>klewis</td>\n",
       "      <td>A: Pours a reddish copper with an audibly f...</td>\n",
       "      <td>German Doppelbock</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Left Hand Brewing Company</td>\n",
       "      <td>Goosinator - Smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score             username  \\\n",
       "412226   4.03               cantal   \n",
       "458058   4.00             warnerry   \n",
       "116967   4.00  NorthCoastPranqster   \n",
       "87978    3.88         cvstrickland   \n",
       "319909   3.89               klewis   \n",
       "\n",
       "                                                     text  \\\n",
       "412226                                                      \n",
       "458058                                                 0%   \n",
       "116967                                                      \n",
       "87978      12-ounce longneck poured into my DFH pint g...   \n",
       "319909     A: Pours a reddish copper with an audibly f...   \n",
       "\n",
       "                          style  abv                        brewery_name  \\\n",
       "412226             American IPA  4.9            Oskar Blues Grill & Brew   \n",
       "458058           Belgian Saison  4.2  Crooked Stave Artisan Beer Project   \n",
       "116967  American Imperial Stout  9.5        Great Divide Brewing Company   \n",
       "87978          English Pale Ale  5.4        Great Divide Brewing Company   \n",
       "319909        German Doppelbock  7.7           Left Hand Brewing Company   \n",
       "\n",
       "                                    beer_name  \n",
       "412226                   Pinner Throwback IPA  \n",
       "458058               Vieille Artisanal Saison  \n",
       "116967  Espresso Oak Aged Yeti Imperial Stout  \n",
       "87978                         Denver Pale Ale  \n",
       "319909                    Goosinator - Smoked  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing With Pandas\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "test_data = s3.get_object(Bucket='beer-reviews-models-pb', Key='Rec Automation/Review Data/Retrieval Data/Train/retrieval_train.csv')\n",
    "\n",
    "df_test = pd.read_csv(io.BytesIO(test_data['Body'].read()), index_col=\"Unnamed: 0\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tf_ret_train.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile tf_ret_train.py\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from typing import Dict, Text\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# disable tf logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters- sent by clientt passed as command line args to script\n",
    "    parser.add_argument('--epochs', type=int, default=4)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.5)\n",
    "    parser.add_argument('--returned_recommendations', type=int, default=500)\n",
    "    \n",
    "    # data directories\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "    \n",
    "    # model directory - /opt/ml/model   by default for sagemaker\n",
    "    parser.add_argument(\"--model_dir\", type=str)\n",
    "    parser.add_argument(\"--sm-model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ.get(\"SM_HOSTS\")))\n",
    "    parser.add_argument(\"--current-host\", type=str, default=os.environ.get(\"SM_CURRENT_HOST\"))\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "def get_train_data(train_dir):\n",
    "    \n",
    "    df_train = pd.read_csv(os.path.join(train_dir, 'retrieval_train.csv'), index_col=\"Unnamed: 0\")\n",
    "\n",
    "    print('x train: ', np.shape(df_train))\n",
    "    return df_train\n",
    "\n",
    "\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    \n",
    "    df_beer = df['beer_name'].unique()\n",
    "    df_beer = pd.DataFrame(df_beer, columns = ['beer_name'])\n",
    "    \n",
    "    df_ratings = df[['username', 'beer_name']]\n",
    "    df_ratings = df_ratings.dropna()\n",
    "    \n",
    "    # convert dataframes to tensors\n",
    "    tf_beer_dict = tf.data.Dataset.from_tensor_slices(dict(df_beer))\n",
    "    tf_ratings_dict = tf.data.Dataset.from_tensor_slices(dict(df_ratings))\n",
    "    \n",
    "    # map rows to a dictionary\n",
    "    ratings = tf_ratings_dict.map(lambda x: {\n",
    "        \"beer_name\": x[\"beer_name\"],\n",
    "        \"username\": x[\"username\"]\n",
    "    })\n",
    "    beer_list = tf_beer_dict.map(lambda x: x['beer_name'])\n",
    "    \n",
    "    print('converted df to tensors')\n",
    "    return ratings, beer_list\n",
    "\n",
    "\n",
    "def get_unique_beers_and_users(ratings, beer_list):\n",
    "    usernames = ratings.map(lambda x: x['username'])\n",
    "    unique_users = np.unique(np.concatenate(list(usernames.batch(1000))))\n",
    "    unique_beers = np.unique(np.concatenate(list(beer_list.batch(1000))))\n",
    "\n",
    "    print(\"unique users: \", len(unique_users), \"unique_beers: \", len(unique_beers))\n",
    "    return unique_users, unique_beers\n",
    "\n",
    "    \n",
    "def test_train_split(ratings, df):\n",
    "    tf.random.set_seed(42)\n",
    "    shuffled = ratings.shuffle(len(df), seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "    train = shuffled.take(int(len(df)*0.8))\n",
    "    test = shuffled.skip(int(len(df)*0.8)).take(int(len(df)*0.2))\n",
    "    print(\"test data len: \", len(test), \"train data len: \", len(train))\n",
    "    return test, train\n",
    "    \n",
    "    \n",
    "# extend the tfrs class\n",
    "class BeerRetreival(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        embedding_dims = 32\n",
    "        self.user_model =  tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary= unique_users, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_users)+1, embedding_dims)\n",
    "        ])\n",
    "\n",
    "        self.beer_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_beers, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_beers)+1, embedding_dims)\n",
    "        ])\n",
    "\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "                        metrics=tfrs.metrics.FactorizedTopK(\n",
    "                        candidates=beer_list.batch(128).cache().map(self.beer_model)\n",
    "                        ))\n",
    "        \n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['username'])\n",
    "        beer_embeddings = self.beer_model(features['beer_name'])\n",
    "        return self.task(user_embeddings, beer_embeddings)\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    args, _ = parse_args()\n",
    "    \n",
    "\n",
    "    print('Training data location: {}'.format(args.train))\n",
    "    \n",
    "    df_train = get_train_data(args.train)\n",
    "    ratings, beer_list = df_to_tensor(df_train)\n",
    "    unique_users, unique_beers = get_unique_beers_and_users(ratings, beer_list)\n",
    "    test, train = test_train_split(ratings, df_train)\n",
    "\n",
    "    \n",
    "    returned_recommendations = args.returned_recommendations\n",
    "    epochs = args.epochs\n",
    "    learning_rate = args.learning_rate\n",
    "    #returned_recommendations = 500\n",
    "    #epochs = 4\n",
    "    #learning_rate = 0.5\n",
    "    print('returned reccomendations = {}, epochs = {}, learning rate = {}'.format(returned_recommendations, epochs, learning_rate))\n",
    "    \n",
    "    # create + train model\n",
    "    model = BeerRetreival()\n",
    "    optimizer = tf.keras.optimizers.Adagrad(learning_rate)\n",
    "    model.compile(optimizer)\n",
    "    model.fit(train.batch(8192),\n",
    "             validation_data = test.batch(512),\n",
    "             validation_freq = 2,\n",
    "             epochs = epochs,\n",
    "             verbose = 0)\n",
    "\n",
    "    # Eval model\n",
    "    scores = model.evaluate(test.batch(8192), return_dict=True, verbose=0)\n",
    "\n",
    "    print(\"top 10 score: \", scores['factorized_top_k/top_10_categorical_accuracy'])\n",
    "    print(\"top 50 score: \", scores['factorized_top_k/top_50_categorical_accuracy'])\n",
    "    print(\"top 100 score: \", scores['factorized_top_k/top_100_categorical_accuracy'])\n",
    "\n",
    "    #save model - need to call first\n",
    "    brute_force = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=500)\n",
    "    brute_force.index_from_dataset(\n",
    "        beer_list.batch(128).map(lambda beer_name: (beer_name, model.beer_model(beer_name)))\n",
    "    )\n",
    "\n",
    "    _ = brute_force(np.array([\"pblackburn\"]))\n",
    "    \n",
    "    \n",
    "    if args.current_host == args.hosts[0]:\n",
    "        \n",
    "        print(\"Host arg:\", args.hosts[0])\n",
    "        # save model to an S3 directory with version number '/1' in Tensorflow SavedModel Format\n",
    "        tf.saved_model.save(\n",
    "          brute_force,\n",
    "          os.path.join(args.sm_model_dir, \"01\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow-recommenders\n",
    "pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/aws-samples/amazon-sagemaker-script-mode',\n",
    "#               'branch': 'master' }\n",
    "#local_instance_type = 'local'\n",
    "train_instance_type = 'ml.p2.xlarge'\n",
    "hyperparameters = {'epochs': 4, 'returned_recommendations': 500, 'learning_rate': 0.5}\n",
    "retrieval_estimator = TensorFlow(\n",
    "                            entry_point = 'tf_ret_train.py',\n",
    "                            dependencies=['requirements.txt'],                       \n",
    "                            instance_type = train_instance_type,\n",
    "                            instance_count = 1,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            role=sagemaker.get_execution_role(),\n",
    "                            framework_version='2.5',\n",
    "                            py_version='py37',\n",
    "                            #git_config = git_config\n",
    "                            #script_mode=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:34:37 Starting - Starting the training job...\n",
      "2021-11-20 00:34:39 Starting - Launching requested ML instancesProfilerReport-1637368477: InProgress\n",
      "......\n",
      "2021-11-20 00:35:54 Starting - Preparing the instances for training.........\n",
      "2021-11-20 00:37:34 Downloading - Downloading input data\n",
      "2021-11-20 00:37:34 Training - Downloading the training image.....................\n",
      "2021-11-20 00:41:08 Training - Training image download completed. Training in progress..\u001b[34m2021-11-20 00:41:10.297131: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-20 00:41:10.303675: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-20 00:41:10.436481: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-11-20 00:41:10.562872: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-20 00:41:14,689 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-11-20 00:41:15,210 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-recommenders\u001b[0m\n",
      "\u001b[34mDownloading tensorflow_recommenders-0.6.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/site-packages (from tensorflow-recommenders->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow>=2.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from absl-py>=0.1.6->tensorflow-recommenders->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.12.1)\u001b[0m\n",
      "\u001b[34mCollecting keras<2.8,>=2.7.0rc0\u001b[0m\n",
      "\u001b[34mDownloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.37.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.8,~=2.7.0rc0\u001b[0m\n",
      "\u001b[34mDownloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-io-gcs-filesystem>=0.21.0\u001b[0m\n",
      "\u001b[34mDownloading tensorflow_io_gcs_filesystem-0.22.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting libclang>=9.0.1\u001b[0m\n",
      "\u001b[34mDownloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.34.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cached-property in /usr/local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (58.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (4.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (4.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, keras, tensorflow, tensorflow-recommenders\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tensorflow-estimator\u001b[0m\n",
      "\u001b[34mFound existing installation: tensorflow-estimator 2.5.0\u001b[0m\n",
      "\u001b[34mUninstalling tensorflow-estimator-2.5.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tensorflow-estimator-2.5.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mtensorflow-gpu 2.5.1 requires tensorflow-estimator<2.6.0,>=2.5.0, but you have tensorflow-estimator 2.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed keras-2.7.0 libclang-12.0.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 tensorflow-recommenders-0.6.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2021-11-20 00:42:00,936 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"returned_recommendations\": 500,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model\",\n",
      "        \"epochs\": 4,\n",
      "        \"learning_rate\": 0.5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-11-20-00-34-37-245\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tf_ret_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tf_ret_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":4,\"learning_rate\":0.5,\"model_dir\":\"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model\",\"returned_recommendations\":500}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tf_ret_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tf_ret_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":4,\"learning_rate\":0.5,\"model_dir\":\"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model\",\"returned_recommendations\":500},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-11-20-00-34-37-245\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/source/sourcedir.tar.gz\",\"module_name\":\"tf_ret_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tf_ret_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"4\",\"--learning_rate\",\"0.5\",\"--model_dir\",\"s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model\",\"--returned_recommendations\",\"500\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_RETURNED_RECOMMENDATIONS=500\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 tf_ret_train.py --epochs 4 --learning_rate 0.5 --model_dir s3://sagemaker-us-east-2-348278147190/tensorflow-training-2021-11-20-00-34-37-245/model --returned_recommendations 500\u001b[0m\n",
      "\u001b[34mTraining data location: /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mx train:  (220614, 7)\u001b[0m\n",
      "\u001b[34mconverted df to tensors\u001b[0m\n",
      "\u001b[34munique users:  7895 unique_beers:  4408\u001b[0m\n",
      "\u001b[34mtest data len:  44122 train data len:  176491\u001b[0m\n",
      "\u001b[34mreturned reccomendations = 500, epochs = 4, learning rate = 0.5\u001b[0m\n",
      "\u001b[34mtop 10 score:  0.011898825876414776\u001b[0m\n",
      "\u001b[34mtop 50 score:  0.10196727514266968\u001b[0m\n",
      "\u001b[34mtop 100 score:  0.19915235042572021\u001b[0m\n",
      "\u001b[34mHost arg: algo-1\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34m2021-11-20 00:44:55,176 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-11-20 00:45:16 Uploading - Uploading generated training model\n",
      "2021-11-20 00:45:16 Completed - Training job completed\n",
      "Training seconds: 475\n",
      "Billable seconds: 475\n"
     ]
    }
   ],
   "source": [
    "ret_train_data_loc = \"s3://beer-reviews-models-pb/Rec Automation/Review Data/Retrieval Data/Train\"\n",
    "\n",
    "retrieval_estimator.fit(ret_train_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {estimator.model_data} ./model/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf ./model/model.tar.gz -C ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = steps.TrainingStep(\n",
    "        \"Training Step\",\n",
    "        estimator = retrieval_estimator,\n",
    "        role=workflow_execution_role,\n",
    "        inputs= ret_train_data_loc,\n",
    "        job_name = execution_input[\"TrainingJobName\"]\n",
    "        #s3_bucket= bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hyperperameter Tuning Job (In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "  'learning_rate': ContinuousParameter(0.001, 0.2, scaling_type=\"Logarithmic\"),\n",
    "  'epochs': IntegerParameter(10, 50),\n",
    "  'batch_size': IntegerParameter(64, 256),\n",
    "}\n",
    "\n",
    "metric_definitions = [{'Name': 'loss',\n",
    "                       'Regex': ' loss: ([0-9\\\\.]+)'},\n",
    "                     {'Name': 'val_loss',\n",
    "                       'Regex': ' val_loss: ([0-9\\\\.]+)'}]\n",
    "\n",
    "objective_metric_name = 'val_loss'\n",
    "objective_type = 'Minimize'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_step = steps.ModelStep(\n",
    "    \"Save Model\",\n",
    "    model = training_step.get_expected_model(), \n",
    "    model_name=execution_input[\"ModelName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Async Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_definition = steps.Chain([\n",
    "    processing_step, training_step, model_step\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Workflow(\n",
    "    name=\"Retrieval_Model_Automation_v1\",\n",
    "    definition = workflow_definition,\n",
    "    role = workflow_execution_role,\n",
    "    execution_input = execution_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Unique Names- \n",
    "processing_job_name = \"SK-processing-{}\".format(uuid.uuid1().hex)\n",
    "training_job_name = \"TFRS-Retrieval-training-{}\".format(uuid.uuid1().hex)\n",
    "model_name = \"TFRS-Retrieval-model-{}\".format(uuid.uuid1().hex)\n",
    "\n",
    "    \n",
    "execution = workflow.execute(\n",
    "    inputs={\n",
    "        \"ProcessingJobName\": processing_job_name,\n",
    "        \"TrainingJobName\": training_job_name ,\n",
    "        \"SaveModelJobName\": model_name,\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_events(html=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
